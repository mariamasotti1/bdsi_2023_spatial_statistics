---
title: "Spatial Statistics"
output: html_document
author: Maria Masotti
date: July 20, 2023

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=F,warning=F)


```


## Libraries

```{r}
if (!require("tidycensus")) install.packages('tidycensus')
if (!require("tidyverse")) install.packages('tidyverse')
if (!require("sf")) install.packages('sf')
if (!require("units")) install.packages('units')
if (!require("ggcorrplot")) install.packages('ggcorrplot')
if (!require("car")) install.packages('car')
if (!require("spdep")) install.packages('spdep')
if (!require("CARBayes")) install.packages('CARBayes')
if (!require("GWmodel")) install.packages('GWmodel')
if (!require("patchwork")) install.packages('patchwork')
library(tidycensus);library(tidyverse)
library(GWmodel)
library(sf);library(CARBayes)
library(spdep);library(units)
library(car);library(ggcorrplot)
library(patchwork)
```


We will pull data from the ACS (American Community Survey) using the `tidycensus` R package: 

```{r}
#| code-line-numbers: "1-12|13-21|22-25"
variables_to_get <- c(
  median_value = "B25077_001",
  median_rooms = "B25018_001",
  median_income = "DP03_0062",
  total_population = "B01003_001",
  median_age = "B01002_001",
  pct_college = "DP02_0068P",
  pct_foreign_born = "DP02_0094P",
  pct_white = "DP05_0077P",
  median_year_built = "B25037_001",
  percent_ooh = "DP04_0046P"
)
housing_data <- get_acs(
  geography = "tract",
  variables = variables_to_get,
  state = "MI",
  county = c("Washtenaw","Wayne","Oakland","Macomb","Livingston"),
  geometry = TRUE,
  output = "wide",
  year = 2020
) 
housing_data<-housing_data%>%
  dplyr::select(!ends_with("M"),-NAME) %>%     #remove margin of error
  rename_with(.fn = ~str_remove(.x, "E$")) %>%     #remove "E" 
  na.omit()
```

## Mapping MHV with `ggplot2`

```{r}
mhv_map <- ggplot(housing_data, aes(fill = median_value)) + 
  geom_sf(color = NA) + 
  scale_fill_viridis_c(labels = scales::label_dollar()) + 
  theme_void() + 
  labs(fill = "Median home value ")
mhv_map
```

## Goal 1

- I'm looking to buy a house in SE Michigan. 
- I want a bargain in a desirable area
- Let's look for tracts that are relatively cheap but surrounded by relatively expensive areas.

## Local spatial autocorrelation

First, we need to quantify the extent to which each tract is similar or different from its neighboring tracts. This is akin to calculating local spatial autocorrelation.

We can determine local spatial autocorrelation using a local Moran's I statistic (LISA).

$$
I_i=\frac{(v_i-\bar{v})}{\sum_k (v_k-\bar{v})^2/(n-1)}\sum_jw_{ij}(v_j-\bar{v})
$$ where $w_{ij}$ is 1 if tract $i$ and $j$ are neighbors and 0 if not, and $v_i$ is the MHV at tract $i$.

Positive values indicate spatial clustering (close tracts have similar MHV). Negative values indicate potential outliers (close tracts have different MHV).

## Coding Neighbors in R with `spdep`

Recall $w_{ij}'s$ are equal to 1 if tract $i$ is bordering tract $j$ and 0 if not. We can find the $w_{ij}'s$ in R and visualize the neighborhood graph for SE MI.

```{r}
neighbors <- poly2nb(housing_data)
```



```{r}
housing_coords <- housing_data %>%
  st_centroid() %>%
  st_coordinates()

plot(housing_data$geometry)
plot(neighbors, 
     coords = housing_coords, 
     add = TRUE, 
     col = "blue", 
     points = FALSE)
```



Then we can define the spatial weights with a binary scheme where $w_{ij}$ is 1 if tract $i$ and $j$ are neighbors (connected by blue line) and 0 if not.

```{r}
weights <- nb2listw(neighbors, style = "B")
```

## Calculating Local Moran's I in R

Now, back to calculating local autocorrelation via Local Moran's I:

```{r}
#| code-line-numbers: "1-4|5-7|9-14"

housing_moran <- localmoran(
  housing_data$median_value, 
  weights, 
  alternative = "two.sided"
) %>%
  as_tibble() %>%
  set_names(c("local_i", "exp_i", "var_i", "z_i", "p_i"))

```


```{r}
housing_moran_df <- housing_data %>%
  bind_cols(housing_moran)
ggplot(housing_moran_df, aes(fill = as.numeric(local_i)) )+ 
  geom_sf(size = 0.1) + 
  theme_void() + 
  scale_fill_distiller(palette = "RdYlBu")
```


## Defining clusters based on Local Moran's I

Recall, I am looking for a neighborhood that is cheaper than average but surrounded by neighborhoods that are expensive. We will define 4 clusters:

-   High-high: high MHV, positive I

-   High-low: high MHV, negative I

-   Low-low: low MHV, positive I

-   Low-high: low MHV, negative I

```{r}
housing_moran_clusters <- housing_moran_df %>%
  mutate(cluster = case_when(
    p_i>.05~"Not signif",
    median_value > mean(median_value) & local_i > 0 ~ "High-high",
    median_value > mean(median_value) & local_i < 0 ~ "High-low",
    median_value < mean(median_value) & local_i > 0 ~ "Low-low",
    median_value < mean(median_value) & local_i < 0 ~ "Low-high"
  ))

```



```{r}
color_values <- c(`High-high` = "red", 
                  `High-low` = "pink", 
                  `Low-low` = "blue", 
                  `Low-high` = "lightblue",
                  `Not signif` = "white")

ggplot(housing_moran_clusters, aes(fill = cluster)) + 
  geom_sf(size = 0.1) + 
  theme_void() + 
  scale_fill_manual(values = color_values) + 
  labs(fill = "Cluster type")
```

## Goal 2

Now I want to investigate which factors influence MHV in SE Michigan.

We can proceed by building a model for MHV with available predictors from the survey data we already pulled.


First, let's inspect the distribution of MHV:

```{r}


mhv_histogram <- ggplot(housing_data, aes(x = median_value)) + 
  geom_histogram(alpha = 0.5,
                 bins = 100) + 
  theme_minimal() + 
  scale_x_continuous(labels = scales::label_number_si(accuracy = 0.1)) + 
  labs(x = "Median home value")

mhv_histogram
```

The distribution of MHV is "right-skewed". This violates the assumption that the outcome is Gaussian or Normal for linear regression modeling.


Let's try a log transformation:

```{r}
mhv_histogram_log <- ggplot(housing_data, aes(x = log(median_value))) + 
  geom_histogram(alpha = 0.5, 
                 bins = 100) + 
  theme_minimal() + 
  scale_x_continuous() + 
  labs(x = "Median home value (log)")

 mhv_histogram_log
```



Let's calculate a few variables that will be useful in modeling. We will create

-   `pop_density` as the total population of the census tract divided by the area of the census tract

-   `median_structure_age` as the median age of the structures within the census tract

```{r}
housing_data_for_model <- housing_data %>%
  mutate(pop_density = as.numeric(set_units(total_population / st_area(.), "1/km2")),
         median_structure_age = 2018 - median_year_built) 
```



## A model

Let's fit this linear regression model:

$$
\log(MHV_i)=\alpha + \beta_1*(\text{median_rooms}_i) + \beta_2*(\text{median_income}_i) + \\ \beta_3*(\text{pct_college}_i) + \beta_4*(\text{pct_foreign_born}_i) + \\ \beta_5*(\text{pct_white}_i)
+ \beta_6*(\text{median_age}_i) + \\ \beta_7*(\text{median_structure_age}_i) + \beta_8*(\text{percent_ooh}_i) + \\ \beta_9*(\text{pop_density}_i) + \epsilon_i\\
$$

For simplicity we can write:

$$
log(MHV_i)=\alpha + \sum_{p=1}^9{X}_{pi}{\beta}_p+\epsilon_i
$$



## A model in R

```{r}
#| code-line-numbers: "1|3|5"
formula <- "log(median_value) ~ median_rooms + median_income + pct_college + pct_foreign_born + pct_white + median_age + median_structure_age + percent_ooh + pop_density"

model1 <- lm(formula = formula, data = housing_data_for_model)

summary(model1)

```

Anything unexpected in these results?



## Multicollinearity

Let's investigate potential multicollinearity in our data by visually checking for highly correlated variables. A correlation matrix plot is useful here:

```{r}
#| code-line-numbers: "1-3|5"
estimates <- housing_data_for_model %>%
  dplyr::select(-GEOID, -median_value, -median_year_built,-total_population) %>%
  st_drop_geometry()

correlations <- cor(estimates, method = "pearson")

```

```{r}
ggcorrplot(correlations,method="circle",type="upper")
```



We can also calculate the variance inflation factor (VIF) for each variable. The VIF is the ratio of the variance of estimating each coefficient in a multiple regression model by the variance of a model constructed using only one term. A VIF of 1 indicates no collinearity; VIF values above 5 suggest a level of collinearity that has problematic influence on model interpretation.

```{r}
vif(model1)
```

`median_income` has a VIF of over 7. A potential solution involves removing this variable and re-running the model; as it is highly correlated with other predictors in the model, the effect of median household income would in theory be captured by the remaining predictors.



## Another model in R

Dropping the `median_income` variable:

```{r}
#| code-line-numbers: "1|3|5"
formula2 <- "log(median_value) ~ median_rooms +  pct_college + pct_foreign_born + pct_white + median_age + median_structure_age + percent_ooh + pop_density"

model2 <- lm(formula = formula2, data = housing_data_for_model)

summary(model2)
```

## Model diagnostics

Residuals should be Gaussian distributed, independent, constant variance.

```{r}
housing_data_for_model$residuals <- residuals(model2)
housing_data_for_model$fitted <- fitted(model2)

diagnostic1<-ggplot(housing_data_for_model, aes(x = residuals)) + 
  geom_histogram(bins = 100, alpha = 0.5) + 
  theme_minimal()

diagnostic2<-ggplot(housing_data_for_model, aes(y = residuals,x=fitted)) + 
  geom_point(alpha=.5) +
  geom_smooth() + 
  theme_minimal()

diagnostic1+diagnostic2
```

Independent? Let's check.

## Assessing Spatial Autocorrelation

Spatial autocorrelation is a measure of similarity between nearby observations in space. Let's check for spatial autocorrelation in the residuals from model 2:

```{r}

housing_data_for_model%>%ggplot(aes(fill = residuals)) + 
  geom_sf(color = NA) + 
  scale_fill_viridis_c() + 
  theme_void() + 
  labs(fill = "Residual")

```


## Global Moran's I statistic

We can compute a global level of spatial autocorrealtion of the model residuals to see if the residuals are correlated in space.

$$
I=\frac{N}{W}\frac{\sum_i\sum_j w_{ij}(r_i-\bar{r})(r_j-\bar{r})}{\sum_i(r_i-\bar{r})^2}
$$

where $w_{ij}$ is the "spatial weight" between tract $i$ and tract $j$, $N$ is the number of tracts, $W$ is the sum of the $w_{ij}$'s, $r_i$ is the residual at tract $i$, $\bar{r}$ is the mean residual.

The form of Moran's I is a weighted sum of cross-products of deviations from the mean. When values for features $i$ and $j$ are both larger or smaller than the mean, the cross product will be positive. When one is smaller and one is larger, the cross product will be negative. If the values in a data set tend to cluster spatially (high near high and low near low), I will be positive. If like values tend to repel each other, I will be negative. If values are randomly dispersed, I will be near zero.


We will use the spatial weights from before and compute global Moran's I.

```{r}
moran.test(housing_data_for_model$residuals, weights)
```

Moran's I is about 0.2 which is significantly higher than 0 indicating spatial autocorrelation in the residuals. So our model is misspecified!

## CAR model

We can account for the spatial autocorrelation in the outcome MHV by adding an additional term to the linear regression model:

$$
Y_i \sim \alpha + \sum_{p=1}^P{X}_{pi}{\beta}_p+\phi_i
$$

The $\phi_i$ is the spatial random effect for tract $i$. In a Bayesian context we specify a prior for $\phi_i$ with the following form:

$$
\phi_i|\boldsymbol{\phi}_{-i},\boldsymbol{W},\tau^2,\rho \sim N\bigg(\frac{\rho\sum_jw_{ij}\phi_j}{\rho\sum_jw_{ij}+1-\rho},\frac{\tau^2}{\rho\sum_jw_{ij}+1-\rho}\bigg)
$$

The spatial effect at tract $i$ follows a Gaussian distribution with the mean proportional to the weighted sum of the spatial effects at neighboring tracts. This will induce spatial autocorrelation in the outcome variable, MHV.

## Fitting a CAR model in R using `CARBayes`

The CAR model requires MCMC to estimate the posterior distribution of the model parameters. We need to specify $W$, the neighborhood matrix. We will again use the binary coding scheme which gives a weight of 1 if two tracts share a border and 0 if not.

```{r message=F, warning=F, results='hide'}

CARmodel <- S.CARleroux(formula=formula2, data=housing_data_for_model, 
                        family="gaussian", W=listw2mat(weights), 
                        burnin=10000, n.sample=50000)

```



With the posterior samples we can calculate 95% credible intervals and Bayesian p-values.

```{r}
#| code-line-numbers: "1-2|3-5|6-7"
beta.samples.matrix <- rbind(CARmodel$samples$beta)
colnames(beta.samples.matrix) <- colnames(CARmodel$X)
mcmc.p<-function(x){
  2*min(length(which(x<0))/length(x),length(which(x>0))/length(x))
}
round(t(rbind(estimate=apply(beta.samples.matrix, 2, mean), apply(beta.samples.matrix,
2, quantile, c(0.025, 0.975)),p=apply(beta.samples.matrix,2,mcmc.p))), 5)
```

For the most part, the estimates from the CAR model are in agreement with the non-spatial linear regression model. However, `pop_density` changed directionality and lost significance. 



## Model diagnostics CAR model

```{r}
#| code-line-numbers: "1|3"
housing_data_for_model$car_residuals<-CARmodel$residuals$response

moran.test(housing_data_for_model$car_residuals, weights)
```

Now, the I statistic is negative with p-value=1. There is no longer any evidence that residuals are spatially autocorrelated.



## Goal 3: Explore non-stationarity in the predictors

The CAR model estimates global associations between the outcome variable, MHV, and its predictors. This lends itself to conclusions like "In SE Michigan, higher levels of educational attainment are associated with higher MHVs." However, it is possible that a realtionship between outcome and predictor may vary from neighborhood to neighborhood. This phenomenon is called spatial non-stationarity.




## GWR

Geographically weighted regression (GWR) is designed to evaluate local variations in the results of regression models. The basic form of GWR for tract $i$ can be written as:

$$
log(MHV_i)=\alpha_i + \sum_{p=1}^P\beta_{ip}X_{ip}+\epsilon_i
$$

where $P$ is the number of predictors. Contrasting this with the previously defined model:

$$
log(MHV_i)=\alpha + \sum_{p=1}^P\beta_{p}X_{ip}+\epsilon_i
$$


## Data borrowing

GWR uses a moving-window weighting technique to obtain separate regression equations for each spatial location. For a target tract, neighboring tracts are weighted based on a distance decay function. Closer locations will have greater influence on the results for the local model and further locations will have less influence.


## Distance-decay functions

::: columns
::: {.column width="40%"}
-   The form of the distance decay function must be specified.
-   Examples are Gaussian, Bi-square, and Exponential.
-   They differ in the rate at which the spatial weights decline.

Gaussian: $w_{ij}=\exp(-\frac{d_{ij}^2}{h^2})$

Exponential: $w_{ij}=\exp(-\frac{d_{ij}}{h})$

Bi-square: $w_{ij}=1-(\frac{d_{ij}^2}{h^2})^2$
:::

::: {.column width="60%"}

:::
:::





## Bandwidth

The bandwidth, h, is a parameter of the distance decay function and can be specified by the user or chosen via cross-validation. In an adaptive GWR the bandwidth is the nearest neighbor at which the weights fall to zero, or approximately zero.

-   small bandwidth = restricts data included in local regression to only those recorded in close proximity to the regression point

-   large bandwidth = data from locations further away influence the local regression

-   Bias - variance trade-off

    -   larger bandwidth -\> larger bias

    -   smaller bandwidth -\> larger variance
    


## Fitting GWR model with `GWmodel`

We will set the bandwidth to 100 and use the bi-square decay function. This means that the local regression model fit at tract $i$ uses data from only the 100 nearest neighbors. Once the bandwidth is chosen we can run the model and plot the results:

```{r}
#| code-line-numbers: "1-2|4-10|12-13"
housing_data_sp <- housing_data_for_model %>%
   as_Spatial()

gw_model <- gwr.basic(
  formula = formula2, 
  data = housing_data_sp, 
  bw = 100,
  kernel = "bisquare",
  adaptive = TRUE
)

gw_model_results <- gw_model$SDF %>%
  st_as_sf() 

```


We can plot local $R^2$ estimates to assess how the model is fitting locally:

```{r}
ggplot(gw_model_results, aes(fill = Local_R2)) + 
  geom_sf(color = NA) + 
  scale_fill_viridis_c() + 
  theme_void() + 
  labs(fill = "Local R^2")
```

The model doesn't fit as well in some edge areas. 



```{r}
ggplot(gw_model_results, aes(fill = pct_college)) + 
  geom_sf(color = NA) + 
  scale_fill_viridis_c() + 
  theme_void() + 
  labs(fill = "Local β for \npct_college")
```

In the global model, percent with a college degree is positively associated with MHV. It seems this relationship is even stronger in the neighborhoods immediately surrounding downtown Detroit.



```{r}
ggplot(gw_model_results, aes(fill = percent_ooh)) + 
  geom_sf(color = NA) + 
  scale_fill_viridis_c() + 
  theme_void() + 
  labs(fill = "Local β for \npercent_ooh")

```

In the global model, percent owner-occupied is negatively associated with MHV. It seems this relationship is strongest in downtown Detroit. Suburban areas surrounding Detroit tend to have more positive associations between percent owner-occupied and MHV.


```{r}
ggplot(gw_model_results, aes(fill = median_rooms)) + 
  geom_sf(color = NA) + 
  scale_fill_viridis_c() + 
  theme_void() + 
  labs(fill = "Local β for \nmedian_rooms")
```

The local estimates for the effect of median rooms tends to be consistent over the area except for a few spots. The upper right hand corner of the map is near / on the lake. Homes on the waterfront in this area tend to be very expensive and may be influencing local estimates here.



## Resources

-   Point pattern data: [spatstat.org](https://spatstat.org)

-   [Areal & geostatistical data modeling with INLA](https://www.paulamoraga.com/book-geospatial/sec-arealdatatheory.html)

-   [GWR](https://gistbok.ucgis.org/bok-topics/geographically-weighted-regression-framework)
